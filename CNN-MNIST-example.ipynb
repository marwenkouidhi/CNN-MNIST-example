{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 530
    },
    "colab_type": "code",
    "id": "Rlp5wUW_FDmH",
    "outputId": "375cb352-57f9-4bc4-aa5b-8a9824e8cad2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-16 13:31:18.962473: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-16 13:31:19.003701: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-16 13:31:19.004174: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-16 13:31:19.598691: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/user01/miniconda3/envs/lab/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Importing the relevant packages\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading and preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before continuing with our model and training, our first job is to preprocess the dataset\n",
    "# This is a very important step in all of machine learning\n",
    "\n",
    "# The MNIST dataset is, in general, highly processed already - after all its 28x28 grayscale images of clearly visible digits\n",
    "# Thus, our preprocessing will be limited to scaling the pixel values, shuffling the data and creating a validation set\n",
    "\n",
    "# NOTE: When finally deploying a model in practice, it might be a good idea to include the prerpocessing as initial layers\n",
    "# In that way, the users could just plug the data (images) directly, instead of being required to resize/rescale it before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "9S6uGLzkFDmP",
    "outputId": "6a5bad6b-035f-4f2e-a81c-8015e17001f4"
   },
   "outputs": [],
   "source": [
    "# Defining some constants/hyperparameters\n",
    "BUFFER_SIZE = 70_000 # for reshuffling\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "9S6uGLzkFDmP",
    "outputId": "6a5bad6b-035f-4f2e-a81c-8015e17001f4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-16 13:31:20.450543: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-16 13:31:20.450980: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "# Downloading the MNIST dataset\n",
    "\n",
    "# When 'with_info' is set to True, tfds.load() returns two variables: \n",
    "# - the dataset (including the train and test sets) \n",
    "# - meta info regarding the dataset itself\n",
    "\n",
    "mnist_dataset, mnist_info = tfds.load(name='mnist', with_info=True, as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "9S6uGLzkFDmP",
    "outputId": "6a5bad6b-035f-4f2e-a81c-8015e17001f4"
   },
   "outputs": [],
   "source": [
    "# Extracting the train and test datasets\n",
    "mnist_train, mnist_test = mnist_dataset['train'], mnist_dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "9S6uGLzkFDmP",
    "outputId": "6a5bad6b-035f-4f2e-a81c-8015e17001f4"
   },
   "outputs": [],
   "source": [
    "# Creating a function to scale our image data (it is recommended to scale the pixel values in the range [0,1] )\n",
    "def scale(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image /= 255.\n",
    "\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the data\n",
    "train_and_validation_data = mnist_train.map(scale)\n",
    "test_data = mnist_test.map(scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "9S6uGLzkFDmP",
    "outputId": "6a5bad6b-035f-4f2e-a81c-8015e17001f4"
   },
   "outputs": [],
   "source": [
    "# Defining the size of the validation set\n",
    "num_validation_samples = 0.1 * mnist_info.splits['train'].num_examples\n",
    "num_validation_samples = tf.cast(num_validation_samples, tf.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "9S6uGLzkFDmP",
    "outputId": "6a5bad6b-035f-4f2e-a81c-8015e17001f4"
   },
   "outputs": [],
   "source": [
    "# Defining the size of the test set\n",
    "num_test_samples = mnist_info.splits['test'].num_examples\n",
    "num_test_samples = tf.cast(num_test_samples, tf.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "9S6uGLzkFDmP",
    "outputId": "6a5bad6b-035f-4f2e-a81c-8015e17001f4"
   },
   "outputs": [],
   "source": [
    "# Reshuffling the dataset\n",
    "train_and_validation_data = train_and_validation_data.shuffle(BUFFER_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "9S6uGLzkFDmP",
    "outputId": "6a5bad6b-035f-4f2e-a81c-8015e17001f4"
   },
   "outputs": [],
   "source": [
    "# Splitting the dataset into training + validation\n",
    "train_data = train_and_validation_data.skip(num_validation_samples)\n",
    "validation_data = train_and_validation_data.take(num_validation_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "9S6uGLzkFDmP",
    "outputId": "6a5bad6b-035f-4f2e-a81c-8015e17001f4"
   },
   "outputs": [],
   "source": [
    "# Batching the data\n",
    "# NOTE: For proper functioning of the model, we need to create one big batch for the validation and test sets\n",
    "train_data = train_data.batch(BATCH_SIZE)\n",
    "validation_data = validation_data.batch(num_validation_samples) \n",
    "test_data = test_data.batch(num_test_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the model and training it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we have preprocessed the dataset, we can define our CNN and train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "9S6uGLzkFDmP",
    "outputId": "6a5bad6b-035f-4f2e-a81c-8015e17001f4"
   },
   "outputs": [],
   "source": [
    "# Outlining the model/architecture of our CNN\n",
    "# CONV -> MAXPOOL -> CONV -> MAXPOOL -> FLATTEN -> DENSE\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(50, 5, activation='relu', input_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2,2)), \n",
    "    # (2,2) is the default pool size so we could have just used MaxPooling2D() with no explicit arguments\n",
    "    tf.keras.layers.Conv2D(50, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2,2)), \n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(10) # You can apply softmax activation here, see below for comentary\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "___________________________________________________________________________\n",
      " Layer (type)                    Output Shape                  Param #     \n",
      "===========================================================================\n",
      " conv2d (Conv2D)                 (None, 24, 24, 50)            1300        \n",
      "                                                                           \n",
      " max_pooling2d (MaxPooling2D)    (None, 12, 12, 50)            0           \n",
      "                                                                           \n",
      " conv2d_1 (Conv2D)               (None, 10, 10, 50)            22550       \n",
      "                                                                           \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 5, 5, 50)              0           \n",
      "                                                                           \n",
      " flatten (Flatten)               (None, 1250)                  0           \n",
      "                                                                           \n",
      " dense (Dense)                   (None, 10)                    12510       \n",
      "                                                                           \n",
      "===========================================================================\n",
      "Total params: 36,360\n",
      "Trainable params: 36,360\n",
      "Non-trainable params: 0\n",
      "___________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# A brief summary of the model and parameters\n",
    "model.summary(line_length = 75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the loss function\n",
    "\n",
    "# In general, our model needs to output probabilities of each class, \n",
    "# which can be achieved with a softmax activation in the last dense layer\n",
    "\n",
    "# However, when using the softmax activation, the loss can rarely be unstable\n",
    "\n",
    "# Thus, instead of incorporating the softmax into the model itself,\n",
    "# we use a loss calculation that automatically corrects for the missing softmax\n",
    "\n",
    "# That is the reason for 'from_logits=True'\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "9S6uGLzkFDmP",
    "outputId": "6a5bad6b-035f-4f2e-a81c-8015e17001f4"
   },
   "outputs": [],
   "source": [
    "# Compiling the model with Adam optimizer and the cathegorical crossentropy as a loss function\n",
    "model.compile(optimizer='adam', loss=loss_fn, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "9S6uGLzkFDmP",
    "outputId": "6a5bad6b-035f-4f2e-a81c-8015e17001f4"
   },
   "outputs": [],
   "source": [
    "# Defining early stopping to prevent overfitting\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor = 'val_loss',\n",
    "    mode = 'auto',    \n",
    "    min_delta = 0,\n",
    "    patience = 2,\n",
    "    verbose = 0, \n",
    "    restore_best_weights = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "9S6uGLzkFDmP",
    "outputId": "6a5bad6b-035f-4f2e-a81c-8015e17001f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-16 13:31:20.740432: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-04-16 13:31:20.740977: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-04-16 13:31:32.930033: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype string and shape [1]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2023-04-16 13:31:32.930442: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "422/422 - 14s - loss: 0.2718 - accuracy: 0.9241 - val_loss: 0.0883 - val_accuracy: 0.9730 - 14s/epoch - 32ms/step\n",
      "Epoch 2/20\n",
      "422/422 - 12s - loss: 0.0736 - accuracy: 0.9779 - val_loss: 0.0540 - val_accuracy: 0.9873 - 12s/epoch - 27ms/step\n",
      "Epoch 3/20\n",
      "422/422 - 12s - loss: 0.0548 - accuracy: 0.9833 - val_loss: 0.0389 - val_accuracy: 0.9897 - 12s/epoch - 28ms/step\n",
      "Epoch 4/20\n",
      "422/422 - 12s - loss: 0.0434 - accuracy: 0.9867 - val_loss: 0.0388 - val_accuracy: 0.9878 - 12s/epoch - 28ms/step\n",
      "Epoch 5/20\n",
      "422/422 - 12s - loss: 0.0374 - accuracy: 0.9879 - val_loss: 0.0341 - val_accuracy: 0.9900 - 12s/epoch - 28ms/step\n",
      "Epoch 6/20\n",
      "422/422 - 12s - loss: 0.0300 - accuracy: 0.9912 - val_loss: 0.0236 - val_accuracy: 0.9918 - 12s/epoch - 28ms/step\n",
      "Epoch 7/20\n",
      "422/422 - 12s - loss: 0.0285 - accuracy: 0.9911 - val_loss: 0.0295 - val_accuracy: 0.9908 - 12s/epoch - 28ms/step\n",
      "Epoch 8/20\n",
      "422/422 - 12s - loss: 0.0244 - accuracy: 0.9926 - val_loss: 0.0168 - val_accuracy: 0.9933 - 12s/epoch - 28ms/step\n",
      "Epoch 9/20\n",
      "422/422 - 12s - loss: 0.0214 - accuracy: 0.9931 - val_loss: 0.0119 - val_accuracy: 0.9963 - 12s/epoch - 28ms/step\n",
      "Epoch 10/20\n",
      "422/422 - 12s - loss: 0.0194 - accuracy: 0.9936 - val_loss: 0.0166 - val_accuracy: 0.9940 - 12s/epoch - 29ms/step\n",
      "Epoch 11/20\n",
      "422/422 - 12s - loss: 0.0166 - accuracy: 0.9949 - val_loss: 0.0134 - val_accuracy: 0.9962 - 12s/epoch - 27ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f14f00d7b10>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the network\n",
    "model.fit(\n",
    "    train_data, \n",
    "    epochs = NUM_EPOCHS, \n",
    "    callbacks = [early_stopping], \n",
    "    validation_data = validation_data,\n",
    "    verbose = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nFoXl2txFDmV",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-16 13:33:31.963064: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-04-16 13:33:31.963539: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype string and shape [1]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 674ms/step - loss: 0.0280 - accuracy: 0.9905\n"
     ]
    }
   ],
   "source": [
    "# Testing our model\n",
    "test_loss, test_accuracy = model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nFoXl2txFDmV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.0280. Test accuracy: 99.05%\n"
     ]
    }
   ],
   "source": [
    "# Printing the test results\n",
    "print('Test loss: {0:.4f}. Test accuracy: {1:.2f}%'.format(test_loss, test_accuracy*100.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting images and the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-16 13:33:33.599201: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype string and shape [1]\n",
      "\t [[{{node Placeholder/_2}}]]\n",
      "2023-04-16 13:33:33.599597: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype string and shape [1]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    }
   ],
   "source": [
    "# Split the test_data into 2 arrays, containing the images and the corresponding labels\n",
    "for images, labels in test_data.take(1):\n",
    "    images_test = images.numpy()\n",
    "    labels_test = labels.numpy()\n",
    "\n",
    "# Reshape the images into 28x28 form, suitable for matplotlib (original dimensions: 28x28x1)\n",
    "images_plot = np.reshape(images_test, (10000,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAK8AAACuCAYAAABAzl3QAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAFG0lEQVR4nO3dzyt0bRzH8TP3UCg/mpUFVlaSkqSIFBaSnSj+AT9q8i8oVrKSZG+jYSNZKFESs5CywkoWFsiPUsIwz+Kpp56u7+jyY9w+Z96v5bfLmWvq3ek+58zcE0mn0+kAEPTnb28A+CzihSzihSzihSzihSzihSzihSzihSzihaw834WRSCSb+wD+4/vQlzMvZBEvZBEvZBEvZBEvZBEvZBEvZBEvZBEvZBEvZBEvZBEvZBEvZBEvZBEvZBEvZBEvZBEvZBEvZBEvZBEvZBEvZBEvZBEvZBEvZBEvZBEvZBEvZBEvZBEvZBEvZBEvZBEvZBEvZBEvZBEvZBEvZBEvZBEvZBEvZBEvZBEvZBEvZHn/9jDCpbCw0Jx3dHR4H+Px8dGZbW5ufnpPH8WZF7KIF7KIF7KIF7Jy7oItGo06s8nJSXPtwMCA93GtC5VMxz0/Pzfn6XTa+/Ws92HNgiAIJiYmnNng4KC5tqKiwnsPqVTKme3t7Zlr+/v7ndnl5aX3a1k480IW8UIW8UIW8UIW8UJWJO15iRuJRLK9l29VXFxszhOJhDPr6urK9nb+Jx6Pm/Pj42Nn1tfXZ65tbGx0ZvX19V/b2A/LdHfE964LZ17IIl7IIl7IIl7ICsUFW2VlpTNbW1sz19bW1nof9+LiwpmNjIyYa5uampzZ8PCwuTYWi3nv4aclk0lnNjMzY669ubn50mttbW2Zcy7YEHrEC1nEC1nEC1nEC1mhuNuwsbHhzD7yLVjrrkIQBEFPT48zOzo68j7uzs6OOW9ubvY+xkc8PT2Z88XFRWc2NTVlrrU+IG59SzibuNuA0CNeyCJeyCJeyArFt4c7OzudWaZ/9L++vnr9fRAEwcnJydc29g1ub2/N+dLSkjObnp42156dnX3nln4NzryQRbyQRbyQRbyQRbyQFYrHw9ZbeHt7M9e+vLw4s4KCgm/fUxAEQV1dnTkfHx835/f3985sfn7eXHt6evrpff12PB5G6BEvZBEvZBEvZIXigm12dtaZjY6Oev/92NiYObc+B/vw8OC/MXwKF2wIPeKFLOKFLOKFLOKFrFDcbSgpKXFmy8vL5tqPfKt4e3vbmXV3d5trn5+fvY+L93G3AaFHvJBFvJBFvJAVigs2S1lZmTlfWVlxZu3t7d7H3d/fN+ctLS3ex8D7uGBD6BEvZBEvZBEvZBEvZIX2bkMmRUVFzmx9fd1c29ra6n3chYUFZ5bpW8I8Sn4fdxsQesQLWcQLWcQLWTl3wWYpLS0154lEwpl95PPAbW1t5nx3d9f7GLmICzaEHvFCFvFCFvFCFvFCFncb3tHQ0ODMrG8UB4H92Hlubs5cG4/Hv7SvsONuA0KPeCGLeCGLeCErFL89nC0HBwfO7O7uzlxrXbBVVVWZa6PRqDm3fhcZmXHmhSzihSzihSzihSzihaycu9uQl+e+5Uy/75tMJp1ZLBbzfq3e3l5znukYV1dX3scGZ14II17IIl7IIl7IyrnP81oXbIeHh+bampqarOyhvLzcnHPB9i8+z4vQI17IIl7IIl7IIl7IyrnHw6lUypll+v/HhoaGnFl+fr65trq62pmtrq6aa6+vr9/bIjxx5oUs4oUs4oUs4oWsnHs8jN+Px8MIPeKFLOKFLOKFLOKFLOKFLOKFLOKFLOKFLOKFLOKFLOKFLOKFLOKFLOKFLOKFLO9vD/t+QBj4KZx5IYt4IYt4IYt4IYt4IYt4IYt4IYt4IYt4Iesf6XIjavaLCioAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 5\n"
     ]
    }
   ],
   "source": [
    "# The image to be displayed and tested\n",
    "i = 502\n",
    "\n",
    "\n",
    "# Plot the image\n",
    "plt.figure(figsize=(2, 2))\n",
    "plt.axis('off')\n",
    "plt.imshow(images_plot[i-1], cmap=\"gray\", aspect='auto')\n",
    "plt.show()\n",
    "\n",
    "# Print the correct label for the image\n",
    "print(\"Label: {}\".format(labels_test[i-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 60ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 10 artists>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Obtain the model's predictions (logits)\n",
    "predictions = model.predict(images_test[i-1:i])\n",
    "\n",
    "# Convert those predictions into probabilities (recall that we incorporated the softmaxt activation into the loss function)\n",
    "probabilities = tf.nn.softmax(predictions).numpy()\n",
    "# Convert the probabilities into percentages\n",
    "probabilities = probabilities*100\n",
    "\n",
    "\n",
    "# Create a bar chart to plot the probabilities for each class\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.bar(x=[1,2,3,4,5,6,7,8,9,10], height=probabilities[0], tick_label=[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "defaultNotebook.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "lab",
   "language": "python",
   "name": "lab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
